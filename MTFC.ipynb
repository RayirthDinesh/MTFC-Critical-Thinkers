{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rayir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rayir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rayir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 16.671719296084092\n",
      "Accuracy: 0.6764705882352942\n",
      "Predictions: [0, 1, 1, 1, 1]\n",
      "Actual values: [0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "dftrans = pd.read_csv('BETTER30.csv')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, float):\n",
    "        return \"\"  \n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = text.split(\" \")\n",
    "    cleaned = []\n",
    "    for token in tokens:\n",
    "        lemmatized_token = wnl.lemmatize(token)\n",
    "        if lemmatized_token not in stop_words:\n",
    "            cleaned.append(lemmatized_token)\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "scam_labels = [\n",
    "    'scam', 'suspicious', 'highly_suspicious', 'slightly_suspicious', 'potential_scam',\n",
    "    'scam_response', 'citing urgency', 'suggesting a dangerous situation', 'dismissive official protocols'\n",
    "]\n",
    "non_scam_labels = [\n",
    "    'neutral', 'legitimate', 'standard_opening', 'identification_request', 'polite_ending',\n",
    "    'adhering to protocols', 'emphasizing security and compliance', 'ready for further engagement'\n",
    "]\n",
    "\n",
    "def categorize_label(label):\n",
    "    if label in scam_labels:\n",
    "        return 0\n",
    "    elif label in non_scam_labels:\n",
    "        return 1\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "dftrans['CONTEXT'] = dftrans['CONTEXT'].fillna('unknown')\n",
    "dftrans['FEATURES'] = dftrans['FEATURES'].fillna('unknown')\n",
    "\n",
    "dftrans.dropna(subset=['TEXT', 'LABEL'], inplace=True)\n",
    "\n",
    "if 'ANNOTATIONS' in dftrans.columns:\n",
    "    dftrans.drop(columns=['ANNOTATIONS'], inplace=True)\n",
    "\n",
    "dftrans['TEXT'] = dftrans['TEXT'].apply(clean_text)\n",
    "dftrans['CONTEXT'] = dftrans['CONTEXT'].apply(clean_text)\n",
    "\n",
    "dftrans['LABEL'] = dftrans['LABEL'].apply(categorize_label)\n",
    "\n",
    "dftrans.dropna(subset=['LABEL'], inplace=True)\n",
    "\n",
    "dftrans['COMBINED'] = dftrans['TEXT'] + \" \" + dftrans['CONTEXT']\n",
    "\n",
    "X = dftrans['COMBINED']\n",
    "y = dftrans['LABEL']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "y_pred_binary = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "y_pred_binary_int = [int(pred) for pred in y_pred_binary]\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary_int)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Predictions: {y_pred_binary[:5]}\")\n",
    "print(f\"Actual values: {y_pred_binary_int[:5]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
